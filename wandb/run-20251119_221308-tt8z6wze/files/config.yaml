_wandb:
    value:
        cli_version: 0.23.0
        e:
            lrsc3whnqcded9fy4dlewfxifm309gkc:
                args:
                    - --model
                    - Qwen/Qwen3-4B
                    - --data_dir
                    - data/train.jsonl
                    - --layer
                    - "16"
                    - --last_n
                    - "32"
                    - --contrast
                    - plausibility
                    - --out_dir
                    - artifacts_qwen4b
                    - --wandb-mode
                    - online
                    - --wandb-project
                    - semeval-task11
                    - --wandb-run-name
                    - qwen4b_vec_l16
                    - --wandb-upload-vector
                    - --wandb-log-prompts
                    - "20"
                codePath: scripts/compute_vectors.py
                codePathLocal: scripts/compute_vectors.py
                cpu_count: 128
                cpu_count_logical: 128
                cudaVersion: "12.4"
                disk:
                    /:
                        total: "1073741824"
                        used: "11034624"
                email: choudharyramnarayan123@gmail.com
                executable: /home/ramnarayan.ramniwas/anaconda3/bin/python
                git:
                    commit: 98fe35d75ba369f8f8defbd16aa476eb9bc74fb0
                    remote: https://github.com/Ramnarayan-Choudhary/NLP_701.git
                gpu: NVIDIA RTX 5000 Ada Generation
                gpu_count: 8
                gpu_nvidia:
                    - architecture: Ada
                      cudaCores: 12800
                      memoryTotal: "34351349760"
                      name: NVIDIA RTX 5000 Ada Generation
                      uuid: GPU-c2e1482c-7aeb-e910-bf53-6eaeaca40281
                    - architecture: Ada
                      cudaCores: 12800
                      memoryTotal: "34351349760"
                      name: NVIDIA RTX 5000 Ada Generation
                      uuid: GPU-28306e01-bf49-bf05-b680-9b531d53c1d7
                    - architecture: Ada
                      cudaCores: 12800
                      memoryTotal: "34351349760"
                      name: NVIDIA RTX 5000 Ada Generation
                      uuid: GPU-3905de69-0cb8-64ed-bdbd-22a57c08dac3
                    - architecture: Ada
                      cudaCores: 12800
                      memoryTotal: "34351349760"
                      name: NVIDIA RTX 5000 Ada Generation
                      uuid: GPU-d9aff900-b0b6-2b18-10d7-89db70dd35b2
                    - architecture: Ada
                      cudaCores: 12800
                      memoryTotal: "34351349760"
                      name: NVIDIA RTX 5000 Ada Generation
                      uuid: GPU-2873fcfc-cb9a-263b-df72-472ff61da06a
                    - architecture: Ada
                      cudaCores: 12800
                      memoryTotal: "34351349760"
                      name: NVIDIA RTX 5000 Ada Generation
                      uuid: GPU-afd4705f-40f2-1857-fd9a-4a2980f47eec
                    - architecture: Ada
                      cudaCores: 12800
                      memoryTotal: "34351349760"
                      name: NVIDIA RTX 5000 Ada Generation
                      uuid: GPU-c0a0a118-ac90-a626-16d5-b1a700889823
                    - architecture: Ada
                      cudaCores: 12800
                      memoryTotal: "34351349760"
                      name: NVIDIA RTX 5000 Ada Generation
                      uuid: GPU-a333d841-10e7-c5c9-52b9-5e1ccd5fe21d
                host: gpu-01
                memory:
                    total: "811260125184"
                os: Linux-5.15.173-ql-generic-13.0-17-x86_64-with-glibc2.35
                program: /home/ramnarayan.ramniwas/MS_projects/NLP_701/scripts/compute_vectors.py
                python: CPython 3.10.9
                root: /home/ramnarayan.ramniwas/MS_projects/NLP_701
                slurm:
                    cluster_name: zap
                    conf: /etc/qlustar/common/slurm-llnl/slurm.conf
                    cpu_bind: quiet,mask_cpu:0x0000000000000000000000000000FF00
                    cpu_bind_list: "0x0000000000000000000000000000FF00"
                    cpu_bind_type: 'mask_cpu:'
                    cpu_bind_verbose: quiet
                    cpus_on_node: "8"
                    cpus_per_task: "8"
                    distribution: cyclic
                    gpus_on_node: "1"
                    gtids: "0"
                    job_account: students
                    job_cpus_per_node: "8"
                    job_end_time: "1763604637"
                    job_gid: "2002"
                    job_group: students
                    job_id: "99642"
                    job_name: bash
                    job_nodelist: gpu-01
                    job_num_nodes: "1"
                    job_partition: gpu
                    job_qos: normal
                    job_start_time: "1763575837"
                    job_uid: "2875"
                    job_user: ramnarayan.ramniwas
                    jobid: "99642"
                    launch_node_ipaddr: 10.127.78.115
                    localid: "0"
                    mem_per_node: "49152"
                    mpi_type: pmix
                    nnodes: "1"
                    nodeid: "0"
                    nodelist: gpu-01
                    nprocs: "1"
                    ntasks: "1"
                    pmix_mapping_serv: (vector,(0,1,1))
                    pmixp_abort_agent_port: "46631"
                    prio_process: "0"
                    procid: "0"
                    pty_port: "43241"
                    pty_win_col: "172"
                    pty_win_row: "18"
                    script_context: prolog_task
                    srun_comm_host: 10.127.78.115
                    srun_comm_port: "41377"
                    step_gpus: "0"
                    step_id: "0"
                    step_launcher_port: "41377"
                    step_nodelist: gpu-01
                    step_num_nodes: "1"
                    step_num_tasks: "1"
                    step_tasks_per_node: "1"
                    stepid: "0"
                    submit_dir: /home/ramnarayan.ramniwas/MS_projects/NLP_701
                    submit_host: lo-02
                    task_pid: "3233962"
                    tasks_per_node: "1"
                    topology_addr: gpu-01
                    topology_addr_pattern: node
                    tres_per_task: cpu:8
                    umask: "0022"
                startedAt: "2025-11-19T18:13:08.951539Z"
                writerId: lrsc3whnqcded9fy4dlewfxifm309gkc
        m: []
        python_version: 3.10.9
        t:
            "1":
                - 1
                - 5
                - 11
                - 49
                - 53
                - 71
                - 105
            "2":
                - 1
                - 5
                - 11
                - 49
                - 53
                - 71
                - 105
            "3":
                - 2
                - 13
                - 16
                - 62
            "4": 3.10.9
            "5": 0.23.0
            "6": 4.57.1
            "12": 0.23.0
            "13": linux-x86_64
batch_size:
    value: 4
contrast:
    value: plausibility
data_dir:
    value: data/train.jsonl
last_n:
    value: 32
layer:
    value: 16
max_length:
    value: 2048
model:
    value: Qwen/Qwen3-4B
neg_used:
    value: 486
out_dir:
    value: artifacts_qwen4b
pos_used:
    value: 474
skipped:
    value: 0
total_examples:
    value: 960
